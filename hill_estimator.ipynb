{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ================================================\n",
    "# ========== Hill Tail Index Estimation ==========\n",
    "# ================================================\n",
    "def get_moments_estimates_1(ordered_data):\n",
    "    \"\"\"\n",
    "    Function to calculate first moments array given an ordered data\n",
    "    sequence. Decreasing ordering is required.\n",
    "    Args:\n",
    "        ordered_data: numpy array of ordered data for which\n",
    "                      the 1st moment (Hill estimator)\n",
    "                      is calculated.\n",
    "    Returns:\n",
    "        M1: numpy array of 1st moments (Hill estimator)\n",
    "            corresponding to all possible order statistics\n",
    "            of the dataset.\n",
    "    \"\"\"\n",
    "    logs_1 = np.log(ordered_data)\n",
    "    logs_1_cumsum = np.cumsum(logs_1[:-1])\n",
    "    k_vector = np.arange(1, len(ordered_data))\n",
    "    M1 = (1./k_vector)*logs_1_cumsum - logs_1[1:]\n",
    "    return M1\n",
    "\n",
    "def get_moments_estimates_2(ordered_data):\n",
    "    \"\"\"\n",
    "    Function to calculate first and second moments arrays\n",
    "    given an ordered data sequence. \n",
    "    Decreasing ordering is required.\n",
    "    Args:\n",
    "        ordered_data: numpy array of ordered data for which\n",
    "                      the 1st (Hill estimator) and 2nd moments \n",
    "                      are calculated.\n",
    "    Returns:\n",
    "        M1: numpy array of 1st moments (Hill estimator)\n",
    "            corresponding to all possible order statistics\n",
    "            of the dataset.\n",
    "        M2: numpy array of 2nd moments corresponding to all \n",
    "            possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    logs_1 = np.log(ordered_data)\n",
    "    logs_2 = (np.log(ordered_data))**2\n",
    "    logs_1_cumsum = np.cumsum(logs_1[:-1])\n",
    "    logs_2_cumsum = np.cumsum(logs_2[:-1])\n",
    "    k_vector = np.arange(1, len(ordered_data))\n",
    "    M1 = (1./k_vector)*logs_1_cumsum - logs_1[1:]\n",
    "    M2 = (1./k_vector)*logs_2_cumsum - (2.*logs_1[1:]/k_vector)*logs_1_cumsum\\\n",
    "         + logs_2[1:]\n",
    "    return M1, M2\n",
    "\n",
    "def get_moments_estimates_3(ordered_data):\n",
    "    \"\"\"\n",
    "    Function to calculate first, second and third moments \n",
    "    arrays given an ordered data sequence. \n",
    "    Decreasing ordering is required.\n",
    "    Args:\n",
    "        ordered_data: numpy array of ordered data for which\n",
    "                      the 1st (Hill estimator), 2nd and 3rd moments \n",
    "                      are calculated.\n",
    "    Returns:\n",
    "        M1: numpy array of 1st moments (Hill estimator)\n",
    "            corresponding to all possible order statistics\n",
    "            of the dataset.\n",
    "        M2: numpy array of 2nd moments corresponding to all \n",
    "            possible order statistics of the dataset.\n",
    "        M3: numpy array of 3rd moments corresponding to all \n",
    "            possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    logs_1 = np.log(ordered_data)\n",
    "    logs_2 = (np.log(ordered_data))**2\n",
    "    logs_3 = (np.log(ordered_data))**3\n",
    "    logs_1_cumsum = np.cumsum(logs_1[:-1])\n",
    "    logs_2_cumsum = np.cumsum(logs_2[:-1])\n",
    "    logs_3_cumsum = np.cumsum(logs_3[:-1])\n",
    "    k_vector = np.arange(1, len(ordered_data))\n",
    "    M1 = (1./k_vector)*logs_1_cumsum - logs_1[1:]\n",
    "    M2 = (1./k_vector)*logs_2_cumsum - (2.*logs_1[1:]/k_vector)*logs_1_cumsum\\\n",
    "         + logs_2[1:]\n",
    "    M3 = (1./k_vector)*logs_3_cumsum - (3.*logs_1[1:]/k_vector)*logs_2_cumsum\\\n",
    "         + (3.*logs_2[1:]/k_vector)*logs_1_cumsum - logs_3[1:]\n",
    "    # cleaning exceptional cases\n",
    "    clean_indices = np.where((M2 <= 0) | (M3 == 0) | (np.abs(1.-(M1**2)/M2) < 1e-10)\\\n",
    "                             |(np.abs(1.-(M1*M2)/M3) < 1e-10))\n",
    "    M1[clean_indices] = np.nan\n",
    "    M2[clean_indices] = np.nan\n",
    "    M3[clean_indices] = np.nan\n",
    "    return M1, M2, M3\n",
    "\n",
    "def hill_dbs(ordered_data, t_bootstrap=0.5,\n",
    "             r_bootstrap=500, eps_stop=1.0,\n",
    "             verbose=False, diagn_plots=False):\n",
    "    \"\"\"\n",
    "        Function to perform double-bootstrap procedure for\n",
    "        Hill estimator.\n",
    "        Args:\n",
    "            ordered_data: numpy array for which double-bootstrap\n",
    "                          is performed. Decreasing ordering is required.\n",
    "            t_bootstrap:  parameter controlling the size of the 2nd\n",
    "                          bootstrap. Defined from n2 = n*(t_bootstrap).\n",
    "            r_bootstrap:  number of bootstrap resamplings for the 1st and 2nd\n",
    "                          bootstraps.\n",
    "            eps_stop:     parameter controlling range of AMSE minimization.\n",
    "                          Defined as the fraction of order statistics to consider\n",
    "                          during the AMSE minimization step.\n",
    "            verbose:      flag controlling bootstrap verbosity.\n",
    "            diagn_plots:  flag to switch on/off generation of AMSE diagnostic\n",
    "                          plots.\n",
    "        Returns:\n",
    "            k_star:     number of order statistics optimal for estimation\n",
    "                        according to the double-bootstrap procedure.\n",
    "            x1_arr:     array of fractions of order statistics used for the\n",
    "                        1st bootstrap sample.\n",
    "            n1_amse:    array of AMSE values produced by the 1st bootstrap\n",
    "                        sample.\n",
    "            k1_min:     value of fraction of order statistics corresponding\n",
    "                        to the minimum of AMSE for the 1st bootstrap sample.\n",
    "            max_index1: index of the 1st bootstrap sample's order statistics\n",
    "                        array corresponding to the minimization boundary set\n",
    "                        by eps_stop parameter.\n",
    "            x2_arr:     array of fractions of order statistics used for the\n",
    "                        2nd bootstrap sample.\n",
    "            n2_amse:    array of AMSE values produced by the 2nd bootstrap\n",
    "                        sample.\n",
    "            k2_min:     value of fraction of order statistics corresponding\n",
    "                        to the minimum of AMSE for the 2nd bootstrap sample.\n",
    "            max_index2: index of the 2nd bootstrap sample's order statistics\n",
    "                        array corresponding to the minimization boundary set\n",
    "                        by eps_stop parameter.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print\n",
    "        \"Performing Hill double-bootstrap...\"\n",
    "    n = len(ordered_data)\n",
    "    eps_bootstrap = 0.5 * (1 + np.log(int(t_bootstrap * n)) / np.log(n))\n",
    "    n1 = int(n ** eps_bootstrap)\n",
    "    samples_n1 = np.zeros(n1 - 1)\n",
    "    good_counts1 = np.zeros(n1 - 1)\n",
    "    k1 = None\n",
    "    k2 = None\n",
    "    min_index1 = 1\n",
    "    min_index2 = 1\n",
    "    while k2 == None:\n",
    "        # first bootstrap with n1 sample size\n",
    "        for i in range(r_bootstrap):\n",
    "            sample = np.random.choice(ordered_data, n1, replace=True)\n",
    "            sample[::-1].sort()#从大到小排列\n",
    "            M1, M2 = get_moments_estimates_2(sample)\n",
    "            current_amse1 = (M2 - 2. * (M1) ** 2) ** 2\n",
    "            samples_n1 += current_amse1\n",
    "            good_counts1[np.where(current_amse1 != np.nan)] += 1\n",
    "        averaged_delta = samples_n1 / good_counts1\n",
    "\n",
    "        max_index1 = (np.abs(np.linspace(1. / n1, 1.0, n1) - eps_stop)).argmin()\n",
    "        k1 = np.nanargmin(averaged_delta[min_index1:max_index1]) + 1 + min_index1  # take care of indexing\n",
    "        if diagn_plots:\n",
    "            n1_amse = averaged_delta\n",
    "            x1_arr = np.linspace(1. / n1, 1.0, n1)\n",
    "\n",
    "        # second bootstrap with n2 sample size\n",
    "        n2 = int(n1 * n1 / float(n))\n",
    "        samples_n2 = np.zeros(n2 - 1)\n",
    "        good_counts2 = np.zeros(n2 - 1)\n",
    "\n",
    "        for i in range(r_bootstrap):\n",
    "            sample = np.random.choice(ordered_data, n2, replace=True)\n",
    "            sample[::-1].sort()\n",
    "            M1, M2 = get_moments_estimates_2(sample)\n",
    "            current_amse2 = (M2 - 2. * (M1 ** 2)) ** 2\n",
    "            samples_n2 += current_amse2\n",
    "            good_counts2[np.where(current_amse2 != np.nan)] += 1\n",
    "        max_index2 = (np.abs(np.linspace(1. / n2, 1.0, n2) - eps_stop)).argmin()\n",
    "        averaged_delta = samples_n2 / good_counts2\n",
    "\n",
    "        k2 = np.nanargmin(averaged_delta[min_index2:max_index2]) + 1 + min_index2  # take care of indexing\n",
    "        if diagn_plots:\n",
    "            n2_amse = averaged_delta\n",
    "            x2_arr = np.linspace(1. / n2, 1.0, n2)\n",
    "\n",
    "        if k2 > k1:\n",
    "            print\n",
    "            \"Warning (Hill): k2 > k1, AMSE false minimum suspected, resampling...\"\n",
    "            # move left AMSE boundary to avoid numerical issues\n",
    "            min_index1 = min_index1 + int(0.005 * n)\n",
    "            min_index2 = min_index2 + int(0.005 * n)\n",
    "            k2 = None\n",
    "\n",
    "    '''\n",
    "    # this constant is provided in the Danielsson's paper\n",
    "    # use instead of rho below if needed\n",
    "    rho = (np.log(k1)/(2.*np.log(n1) - np.log(k1)))\\\n",
    "          **(2.*(np.log(n1) - np.log(k1))/(np.log(n1)))\n",
    "    '''\n",
    "\n",
    "    # this constant is provided in Qi's paper\n",
    "    rho = (1. - (2 * (np.log(k1) - np.log(n1)) / (np.log(k1)))) ** (np.log(k1) / np.log(n1) - 1.)\n",
    "\n",
    "    k_star = (k1 * k1 / float(k2)) * rho\n",
    "    k_star = int(np.round(k_star))\n",
    "\n",
    "    # enforce k_star to pick 2nd value (rare cases of extreme cutoffs)\n",
    "    if k_star == 0:\n",
    "        k_star = 2\n",
    "    if int(k_star) >= len(ordered_data):\n",
    "        print\n",
    "        \"WARNING: estimated threshold k is larger than the size of data\"\n",
    "        k_star = len(ordered_data) - 1\n",
    "    if verbose:\n",
    "        print\n",
    "        \"--- Hill double-bootstrap information ---\"\n",
    "        print\n",
    "        \"Size of the 1st bootstrap sample n1:\", n1\n",
    "        print\n",
    "        \"Size of the 2nd bootstrap sample n2:\", n2\n",
    "        print\n",
    "        \"Estimated k1:\", k1\n",
    "        print\n",
    "        \"Estimated k2:\", k2\n",
    "        print\n",
    "        \"Estimated constant rho:\", rho\n",
    "        print\n",
    "        \"Estimated optimal k:\", k_star\n",
    "        print\n",
    "        \"-----------------------------------------\"\n",
    "    if not diagn_plots:\n",
    "        x1_arr, x2_arr, n1_amse, n2_amse = None, None, None, None\n",
    "    return k_star, x1_arr, n1_amse, k1/float(n1), max_index1, x2_arr, n2_amse, k2 / float(n2), max_index2\n",
    "\n",
    "\n",
    "def hill_estimator(ordered_data,\n",
    "                   bootstrap = True, t_bootstrap = 0.5,\n",
    "                   r_bootstrap = 50, verbose = False,\n",
    "                   diagn_plots = False, eps_stop = 0.99):\n",
    "    \"\"\"\n",
    "    Function to calculate Hill estimator for a given dataset.\n",
    "    If bootstrap flag is True, double-bootstrap procedure\n",
    "    for estimation of the optimal number of order statistics is\n",
    "    performed.\n",
    "    Args:\n",
    "        ordered_data: numpy array for which tail index estimation\n",
    "                      is performed. Decreasing ordering is required.\n",
    "        bootstrap:    flag to switch on/off double-bootstrap procedure.\n",
    "        t_bootstrap:  parameter controlling the size of the 2nd\n",
    "                      bootstrap. Defined from n2 = n*(t_bootstrap).\n",
    "        r_bootstrap:  number of bootstrap resamplings for the 1st and 2nd\n",
    "                      bootstraps.\n",
    "        eps_stop:     parameter controlling range of AMSE minimization.\n",
    "                      Defined as the fraction of order statistics to consider\n",
    "                      during the AMSE minimization step.\n",
    "        verbose:      flag controlling bootstrap verbosity. \n",
    "        diagn_plots:  flag to switch on/off generation of AMSE diagnostic\n",
    "                      plots.\n",
    "    Returns:\n",
    "        results: list containing an array of order statistics,\n",
    "                 an array of corresponding tail index estimates,\n",
    "                 the optimal order statistic estimated by double-\n",
    "                 bootstrap and the corresponding tail index,\n",
    "                 an array of fractions of order statistics used for\n",
    "                 the 1st bootstrap sample with an array of corresponding\n",
    "                 AMSE values, value of fraction of order statistics\n",
    "                 corresponding to the minimum of AMSE for the 1st bootstrap\n",
    "                 sample, index of the 1st bootstrap sample's order statistics\n",
    "                 array corresponding to the minimization boundary set\n",
    "                 by eps_stop parameter; and the same characteristics for the\n",
    "                 2nd bootstrap sample.\n",
    "    \"\"\"\n",
    "    k_arr = np.arange(1, len(ordered_data))\n",
    "    xi_arr = get_moments_estimates_1(ordered_data)\n",
    "    if bootstrap:\n",
    "        results = hill_dbs(ordered_data,\n",
    "                           t_bootstrap = t_bootstrap,\n",
    "                           r_bootstrap = r_bootstrap,\n",
    "                           verbose = verbose, \n",
    "                           diagn_plots = diagn_plots,\n",
    "                           eps_stop = eps_stop)\n",
    "        k_star, x1_arr, n1_amse, k1, max_index1, x2_arr, n2_amse, k2, max_index2 = results\n",
    "        while k_star == None:\n",
    "            print(\"Resampling...\")\n",
    "            results = hill_dbs(ordered_data,\n",
    "                           t_bootstrap = t_bootstrap,\n",
    "                           r_bootstrap = r_bootstrap,\n",
    "                           verbose = verbose, \n",
    "                           diagn_plots = diagn_plots,\n",
    "                           eps_stop = eps_stop)\n",
    "            k_star, x1_arr, n1_amse, k1, max_index1, x2_arr, n2_amse, k2, max_index2 = results\n",
    "        xi_star = xi_arr[k_star-1]\n",
    "        #print(\"Adjusted Hill estimated gamma:\", 1 + 1./xi_star)\n",
    "        #print(\"**********\")\n",
    "    else:\n",
    "        k_star, xi_star = None, None\n",
    "        x1_arr, n1_amse, k1, max_index1 = 4*[None]\n",
    "        x2_arr, n2_amse, k2, max_index2 = 4*[None]\n",
    "    results = [k_arr, xi_arr, k_star, xi_star, x1_arr, n1_amse, k1, max_index1,\\\n",
    "               x2_arr, n2_amse, k2, max_index2]\n",
    "    return results\n",
    "\n",
    "def smooth_hill_estimator(ordered_data, r_smooth = 2):\n",
    "    \"\"\"\n",
    "    Function to calculate smooth Hill estimator for a\n",
    "    given ordered dataset.\n",
    "    Args:\n",
    "        ordered_data: numpy array for which tail index estimation\n",
    "                      is performed. Decreasing ordering is required.\n",
    "        r_smooth:     integer parameter controlling the width\n",
    "                      of smoothing window. Typically small\n",
    "                      value such as 2 or 3.\n",
    "    Returns:\n",
    "        k_arr:  numpy array of order statistics based on the data provided.\n",
    "        xi_arr: numpy array of tail index estimates corresponding to \n",
    "                the order statistics array k_arr.\n",
    "    \"\"\"\n",
    "    n = len(ordered_data)\n",
    "    M1 = get_moments_estimates_1(ordered_data)\n",
    "    xi_arr = np.zeros(int(np.floor(float(n)/r_smooth)))\n",
    "    k_arr = np.arange(1, int(np.floor(float(n)/r_smooth))+1)\n",
    "    xi_arr[0] = M1[0]\n",
    "    bin_lengths = np.array([1.]+[float((r_smooth-1)*k) for k in k_arr[:-1]])\n",
    "    cum_sum = 0.0\n",
    "    for i in range(1, r_smooth*int(np.floor(float(n)/r_smooth))-1):\n",
    "        k = i\n",
    "        cum_sum += M1[k]\n",
    "        if (k+1) % (r_smooth) == 0:\n",
    "            xi_arr[int(k+1)/int(r_smooth)] = cum_sum\n",
    "            cum_sum -= M1[int(k+1)/int(r_smooth)]\n",
    "    xi_arr = xi_arr/bin_lengths\n",
    "    return k_arr, xi_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
